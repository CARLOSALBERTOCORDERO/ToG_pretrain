{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "import boto3\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ZipFile(\"dataset.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "def zipdir(path, ziph):\n",
    "    # ziph is zipfile handle\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            ziph.write(os.path.join(root, file))\n",
    "            \n",
    "zipf = zipfile.ZipFile('logs.zip', 'w', zipfile.ZIP_DEFLATED)\n",
    "zipdir('logs/', zipf)\n",
    "zipf.close()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.rmtree('logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.remove(\"DenseNet161Weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket='tog-dataset-sagemaker' # Replace with your s3 bucket name\n",
    "Filename = \"inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "s3 = boto3.Session().resource('s3').Bucket(bucket).Object(Filename).download_file(Filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done writing to s3://sn2020-final-project/InceptionWeights.h5\n"
     ]
    }
   ],
   "source": [
    "bucket='sn2020-final-project' # Replace with your s3 bucket name\n",
    "file = 'InceptionWeights.h5'\n",
    "\n",
    "\n",
    "url = 's3://{}/{}'.format(bucket, file)\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(file).upload_file(file)\n",
    "print('Done writing to {}'.format(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "\n",
    "model_airport_archaeological_site_path = currentPath + os.sep + \"temp\" + os.sep + \"model_airport_archaeological_site\" + os.sep + \"DenseNet161Model.h5\"\n",
    "model_barn_crop_field_path = currentPath + os.sep + \"temp\" + os.sep + \"model_barn_crop_field\" + os.sep + \"DenseNet161Model.h5\"\n",
    "model_dam_factory_path = currentPath + os.sep + \"temp\" + os.sep + \"model_dam_factory\" + os.sep + \"DenseNet161Model.h5\"\n",
    "model_fire_station_golf_course_path = currentPath + os.sep + \"temp\" + os.sep + \"model_fire_station_golf_course\" + os.sep + \"DenseNet161Model.h5\"\n",
    "model_ground_transport_interchange_path = currentPath + os.sep + \"temp\" + os.sep + \"model_ground_transport_interchange\" + os.sep + \"DenseNet161Model.h5\"\n",
    "model_lake_nuclear_path = currentPath + os.sep + \"temp\" + os.sep + \"model_lake_nuclear\" + os.sep + \"DenseNet161Model.h5\"\n",
    "model_office_place_of_workship_path = currentPath + os.sep + \"temp\" + os.sep + \"model_office_place_of_workship\" + os.sep + \"DenseNet161Model.h5\"\n",
    "model_police_railway_bridge_path = currentPath + os.sep + \"temp\" + os.sep + \"model_police_railway_bridge\" + os.sep + \"DenseNet161Model.h5\"\n",
    "model_recreational_facility_shopping_path = currentPath + os.sep + \"temp\" + os.sep + \"model_recreational_facility_shopping\" + os.sep + \"DenseNet161Model.h5\"\n",
    "model_single_unit_stadium_path = currentPath + os.sep + \"temp\" + os.sep + \"model_single-unit_stadium\" + os.sep + \"DenseNet161Model.h5\"\n",
    "model_storage_tower_path = currentPath + os.sep + \"temp\" + os.sep + \"model_storage_tower\" + os.sep + \"DenseNet161Model.h5\"\n",
    "model_tunel_zoo_path = currentPath + os.sep + \"temp\" + os.sep + \"model_tunel_zoo\" + os.sep + \"DenseNet161Model.h5\"\n",
    "model_group1 = currentPath + os.sep + \"temp\" + os.sep + \"model_group1\" + os.sep + \"DenseNet161Model.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadedModel1 = load_model(model_group1)\n",
    "loadedModel2 = load_model(model_barn_crop_field_path)\n",
    "loadedModel3 = load_model(model_ground_transport_interchange_path)\n",
    "\n",
    "\n",
    "\n",
    "path = trainDB + os.sep + \"1_airport\" + os.sep\n",
    "imagesPredict = [f for f in listdir(path) if isfile(join(path,f))]\n",
    "# print(imagesPredict)\n",
    "\n",
    "\n",
    "for file in imagesPredict:\n",
    "    img = load_img(path + file, target_size=( 224, 224))\n",
    "    tensorImage = img_to_array(img) /255.\n",
    "    tensorImage = np.expand_dims(tensorImage, axis=0)\n",
    "    prediction1 = loadedModel1.predict(tensorImage, batch_size = 1)\n",
    "    prediction2 = loadedModel2.predict(tensorImage, batch_size = 1)\n",
    "    prediction3 = loadedModel3.predict(tensorImage, batch_size = 1)\n",
    "\n",
    "    \n",
    "    prediction = np.concatenate((prediction1[0], prediction2[0], prediction3[0]))\n",
    "    #print(prediction)\n",
    "    index = np.where(prediction == max(prediction))[0]\n",
    "    if (0 != index[0].size):\n",
    "        print(\"file \"+ file + \" is: \" + classList[int(index[0])])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
