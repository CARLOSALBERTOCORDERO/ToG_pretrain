{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ZipFile(\"dataset.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import basename\n",
    "\n",
    "# create a ZipFile object\n",
    "with ZipFile('logs.zip', 'w') as zipObj:\n",
    "   # Iterate over all the files in directory\n",
    "   for folderName, subfolders, filenames in os.walk(\"logs\"):\n",
    "       for filename in filenames:\n",
    "           #create complete filepath of file in directory\n",
    "           filePath = os.path.join(folderName, filename)\n",
    "           # Add file to zip\n",
    "           zipObj.write(filePath, basename(filePath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.rmtree('dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.remove(\"DenseNet161Weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket='tog-dataset-sagemaker' # Replace with your s3 bucket name\n",
    "Filename = \"XceptionWeights.h5\"\n",
    "s3 = boto3.Session().resource('s3').Bucket(bucket).Object(Filename).download_file(Filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket='sn2020-final-project' # Replace with your s3 bucket name\n",
    "file = 'DenseNet MLT.ipynb'\n",
    "\n",
    "\n",
    "url = 's3://{}/{}'.format(bucket, file)\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(file).upload_file(file)\n",
    "print('Done writing to {}'.format(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "\n",
    "model_airport_archaeological_site_path = currentPath + os.sep + \"temp\" + os.sep + \"model_airport_archaeological_site\" + os.sep + \"DenseNet161Model.h5\"\n",
    "model_barn_crop_field_path = currentPath + os.sep + \"temp\" + os.sep + \"model_barn_crop_field\" + os.sep + \"DenseNet161Model.h5\"\n",
    "model_dam_factory_path = currentPath + os.sep + \"temp\" + os.sep + \"model_dam_factory\" + os.sep + \"DenseNet161Model.h5\"\n",
    "model_fire_station_golf_course_path = currentPath + os.sep + \"temp\" + os.sep + \"model_fire_station_golf_course\" + os.sep + \"DenseNet161Model.h5\"\n",
    "model_ground_transport_interchange_path = currentPath + os.sep + \"temp\" + os.sep + \"model_ground_transport_interchange\" + os.sep + \"DenseNet161Model.h5\"\n",
    "model_lake_nuclear_path = currentPath + os.sep + \"temp\" + os.sep + \"model_lake_nuclear\" + os.sep + \"DenseNet161Model.h5\"\n",
    "model_office_place_of_workship_path = currentPath + os.sep + \"temp\" + os.sep + \"model_office_place_of_workship\" + os.sep + \"DenseNet161Model.h5\"\n",
    "model_police_railway_bridge_path = currentPath + os.sep + \"temp\" + os.sep + \"model_police_railway_bridge\" + os.sep + \"DenseNet161Model.h5\"\n",
    "model_recreational_facility_shopping_path = currentPath + os.sep + \"temp\" + os.sep + \"model_recreational_facility_shopping\" + os.sep + \"DenseNet161Model.h5\"\n",
    "model_single_unit_stadium_path = currentPath + os.sep + \"temp\" + os.sep + \"model_single-unit_stadium\" + os.sep + \"DenseNet161Model.h5\"\n",
    "model_storage_tower_path = currentPath + os.sep + \"temp\" + os.sep + \"model_storage_tower\" + os.sep + \"DenseNet161Model.h5\"\n",
    "model_tunel_zoo_path = currentPath + os.sep + \"temp\" + os.sep + \"model_tunel_zoo\" + os.sep + \"DenseNet161Model.h5\"\n",
    "model_group1 = currentPath + os.sep + \"temp\" + os.sep + \"model_group1\" + os.sep + \"DenseNet161Model.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadedModel1 = load_model(model_group1)\n",
    "loadedModel2 = load_model(model_barn_crop_field_path)\n",
    "loadedModel3 = load_model(model_ground_transport_interchange_path)\n",
    "\n",
    "\n",
    "\n",
    "path = trainDB + os.sep + \"1_airport\" + os.sep\n",
    "imagesPredict = [f for f in listdir(path) if isfile(join(path,f))]\n",
    "# print(imagesPredict)\n",
    "\n",
    "\n",
    "for file in imagesPredict:\n",
    "    img = load_img(path + file, target_size=( 224, 224))\n",
    "    tensorImage = img_to_array(img) /255.\n",
    "    tensorImage = np.expand_dims(tensorImage, axis=0)\n",
    "    prediction1 = loadedModel1.predict(tensorImage, batch_size = 1)\n",
    "    prediction2 = loadedModel2.predict(tensorImage, batch_size = 1)\n",
    "    prediction3 = loadedModel3.predict(tensorImage, batch_size = 1)\n",
    "\n",
    "    \n",
    "    prediction = np.concatenate((prediction1[0], prediction2[0], prediction3[0]))\n",
    "    #print(prediction)\n",
    "    index = np.where(prediction == max(prediction))[0]\n",
    "    if (0 != index[0].size):\n",
    "        print(\"file \"+ file + \" is: \" + classList[int(index[0])])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
